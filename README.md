# ğŸ§  RAG Conversacional Backend â€“ FastAPI + LangChain + OneDrive

Este backend permite consultas conversacionales sobre documentos almacenados en OneDrive, integrando LangChain, OpenAI y ChromaDB.  
Incluye protecciÃ³n por API Key, memoria por usuario (`chat_id`) y soporte para streaming.

---

## ğŸš€ Funcionalidades

| Endpoint            | DescripciÃ³n                                      |
|---------------------|--------------------------------------------------|
| `GET /query`        | Consulta al RAG con historial por `chat_id`      |
| `GET /query/stream` | (Opcional) Respuesta token a token (stream)     |
| `POST /chat/reset`  | Reinicia la memoria para el `chat_id`           |
| `GET /sync`         | Sincroniza documentos desde carpeta de OneDrive |
| `GET /status`       | Muestra nÃºmero de documentos y Ãºltima sync      |
| `GET /health`       | Devuelve `{"status": "ok"}` si la app estÃ¡ viva |

ğŸ“Œ Todos los endpoints (excepto `/status` y `/health`) requieren autenticaciÃ³n por header `X-API-Key`.

---

## ğŸ” Seguridad por API Key

AÃ±ade en tu `.env`:

```env
API_KEY=mi_super_clave_secreta
```

Y luego en Postman o el frontend, usa el header:

```
X-API-Key: mi_super_clave_secreta
```

---

## ğŸ§  Memoria conversacional por usuario

Cada `chat_id` tiene su propia memoria.  
Puedes resetearla con:

```http
POST /chat/reset?chat_id=usuario123
```

---

## ğŸ“„ SincronizaciÃ³n de documentos (OneDrive)

Los documentos vÃ¡lidos son:

- `.pdf`
- `.docx`
- `.txt`

La app solo re-indexa los documentos nuevos, modificados o eliminados.

---

## ğŸ§± Estructura del proyecto

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py               # Entrypoint FastAPI
â”‚   â”œâ”€â”€ chat_chains.py        # RAG + memoria por chat_id
â”‚   â”œâ”€â”€ callbacks.py          # Streaming token a token
â”‚   â”œâ”€â”€ rag_pipeline.py       # LÃ³gica principal del RAG
â”‚   â”œâ”€â”€ vectorstore.py        # ChromaDB local
â”‚   â”œâ”€â”€ onedrive_sync.py      # IntegraciÃ³n con OneDrive
â”‚   â”œâ”€â”€ cors_config.py        # OrÃ­genes permitidos por entorno
â”œâ”€â”€ snapshot.json             # Metadatos de sincronizaciÃ³n
â”œâ”€â”€ .env                      # Variables sensibles
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
```

---

## ğŸ”§ Variables de entorno (`.env`)

```env
OPENAI_API_KEY=sk-...
API_KEY=mi_super_clave_secreta

O365_CLIENT_ID=...
O365_CLIENT_SECRET=...
O365_TENANT_ID=...
ONEDRIVE_DRIVE_ID=...
ONEDRIVE_FOLDER_PATH=/CHATBOT/conocimiento_chatbot_py

CHROMA_PERSIST_DIRECTORY=./chroma_db
LANGCHAIN_PROJECT=ChatbotHelefante
LANGCHAIN_API_KEY=...
```

---

## ğŸ³ Docker

```bash
docker-compose up --build
```

---

## ğŸŒ CORS

Define orÃ­genes permitidos en `app/cors_config.py`:

```python
ALLOWED_ORIGINS = [
    "http://localhost:3000",        # Desarrollo local
    "https://tufrontend.com"        # ProducciÃ³n
]
```

---

## ğŸ“Š Observabilidad con LangSmith

Este backend envÃ­a trazas a [LangSmith](https://smith.langchain.com) para inspeccionar inputs, outputs y documentos utilizados por el modelo.

---

## ğŸ§© Stack tecnolÃ³gico

- FastAPI
- LangChain
- OpenAI (GPT-4o-mini)
- ChromaDB
- OneDrive (O365)
- Docker
